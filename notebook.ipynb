{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Chicago Active Employee Dataset Analysis\n\nThis notebook provides a comprehensive analysis of the Chicago Active Employee dataset, including:\n\n1. **Data Loading & Preprocessing**: Loading and cleaning the employee data\n2. **Gender Detection**: Enhanced gender classification using name lists\n3. **Exploratory Data Analysis**: Statistical summaries and visualizations\n4. **Feature Engineering**: Creating derived features for analysis\n5. **Clustering Analysis**: K-means clustering to identify employee groups\n6. **Classification Models**: Logistic regression for gender and salary prediction",
      "metadata": {
        "id": "oUuozfGZ65tH"
      }
    },
    {
      "cell_type": "code",
      "source": "# Install required packages\n!pip install pandas openpyxl gender-guesser matplotlib seaborn scikit-learn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYC0YixHqq6K",
        "outputId": "9d546a0d-0ed2-42d9-a371-9411903eff49"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Configuration\nFILE_PATH = 'https://github.com/nluninja/chicago-active-employee-project/raw/refs/heads/main/City%20of%20Chicago%20Active%20Employees%20Dataset.xlsx'\nMALE_FILE = \"https://github.com/nluninja/chicago-active-employee-project/raw/refs/heads/main/M.txt\"\nFEMALE_FILE = \"https://github.com/nluninja/chicago-active-employee-project/raw/refs/heads/main/F.txt\"\nNEUTRAL_FILE = \"https://github.com/nluninja/chicago-active-employee-project/raw/refs/heads/main/N.txt\"\nOUTPUT_FILE = \"chicago_dataset_cleaned.csv\"",
      "metadata": {
        "id": "w0fuvra0kBsE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Import Libraries and Load Data",
      "metadata": {
        "id": "7f5BZ45PwCCc"
      }
    },
    {
      "cell_type": "code",
      "source": "# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport requests\nimport warnings\n\n# Machine learning imports\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n                           silhouette_score, roc_curve, auc, roc_auc_score)\n\n# Gender detection library\nimport gender_guesser.detector as gender\n\n# Configure warnings and plotting style\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)",
      "metadata": {
        "id": "X_9dDs2aj-qW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ntry:\n    df = pd.read_excel(FILE_PATH)\n    print(f\"Dataset loaded successfully. Shape: {df.shape}\")\nexcept FileNotFoundError:\n    print(\"Dataset file not found. Please download it and place it in the correct path.\")\n    print(\"You can often find it by searching 'Current Employee Names, Salaries, and Position Titles Chicago'.\")\n    exit()",
      "metadata": {
        "id": "J9klaAx-wMIp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Initial data exploration\nprint(\"=== Dataset Overview ===\")\nprint(f\"Shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(\"\\n=== Data Info ===\")\nprint(df.info())\nprint(\"\\n=== Missing Values ===\")\nprint(df.isnull().sum())\nprint(\"\\n=== First 5 rows ===\")\nprint(df.head())",
      "metadata": {
        "id": "0Vr5rmcywINY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Data Preprocessing Functions",
      "metadata": {
        "id": "j-ootsQSwQOw"
      }
    },
    {
      "cell_type": "code",
      "source": "def normalize_column_names(df):\n    \"\"\"Normalize column names to lowercase with underscores.\"\"\"\n    def normalize_single_name(col_name):\n        name = str(col_name).lower().strip()\n        name = re.sub(r'[\\s-]+', '_', name)\n        name = re.sub(r'[^a-z0-9_]+', '', name)\n        name = re.sub(r'_+', '_', name)\n        return name\n    \n    df.columns = [normalize_single_name(col) for col in df.columns]\n    return df\n\ndef load_gender_name_lists(male_file, female_file, neutral_file):\n    \"\"\"Load gender name lists from remote files.\"\"\"\n    def load_names_from_url(url):\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            return set(line.strip().lower() for line in response.text.splitlines())\n        except requests.exceptions.RequestException as e:\n            print(f\"Error loading names from {url}: {e}\")\n            return set()\n    \n    male_names = load_names_from_url(male_file)\n    female_names = load_names_from_url(female_file)\n    neutral_names = load_names_from_url(neutral_file)\n    \n    return male_names, female_names, neutral_names\n\ndef classify_gender_from_name(first_name, male_names, female_names, neutral_names):\n    \"\"\"Classify gender based on first name and name lists.\"\"\"\n    if pd.isna(first_name) or not str(first_name).strip():\n        return \"U\"\n    \n    name_clean = str(first_name).strip().split()[0].lower()\n    if not name_clean:\n        return \"U\"\n    \n    if name_clean in male_names:\n        return \"M\"\n    elif name_clean in female_names:\n        return \"F\"\n    elif name_clean in neutral_names:\n        return \"N\"\n    else:\n        return \"U\"\n\ndef process_employee_data(df, male_names, female_names, neutral_names):\n    \"\"\"Process employee data: extract names, classify gender, normalize columns.\"\"\"\n    # Normalize column names\n    df = normalize_column_names(df)\n    \n    # Handle Name column\n    df['name'] = df['name'].fillna('').astype(str)\n    \n    # Extract surname and first name\n    name_parts = df['name'].str.split(',', n=1, expand=True)\n    df['surname'] = name_parts[0].str.strip()\n    \n    first_name_series = name_parts.get(1, pd.Series(index=df.index, dtype=str)).fillna('').str.strip()\n    df['first_name'] = first_name_series.str.split(' ', n=1, expand=True)[0].str.strip()\n    df['first_name'] = df['first_name'].replace('', pd.NA)\n    \n    # Classify gender\n    df['sex'] = df['first_name'].apply(\n        lambda x: classify_gender_from_name(x, male_names, female_names, neutral_names)\n    )\n    \n    # Calculate annual salary for hourly workers\n    mask_hourly = (df['salary_or_hourly'] == 'HOURLY')\n    calculated_values = df.loc[mask_hourly, 'hourly_rate'] * df.loc[mask_hourly, 'typical_hours'] * 52\n    df.loc[mask_hourly, 'annual_salary'] = calculated_values\n    \n    # Remove rows with missing employment type\n    df = df.dropna(subset=['full_or_part_time'])\n    \n    return df",
      "metadata": {
        "id": "iFYjsIamXFYn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "780dc66a-03f0-42d7-e9d5-d96e237223be"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load gender name lists and process data\nprint(\"Loading gender name lists...\")\nmale_names, female_names, neutral_names = load_gender_name_lists(MALE_FILE, FEMALE_FILE, NEUTRAL_FILE)\nprint(f\"Loaded {len(male_names)} male, {len(female_names)} female, and {len(neutral_names)} neutral names.\")\n\nprint(\"\\nProcessing employee data...\")\ndf = process_employee_data(df, male_names, female_names, neutral_names)\nprint(f\"Processed data shape: {df.shape}\")\n\n# Display processed data sample\nprint(\"\\n=== Processed Data Sample ===\")\nprint(df[['name', 'surname', 'first_name', 'sex', 'annual_salary', 'department']].head())",
      "metadata": {
        "id": "MOMus8BqrSID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c2c93f-64a8-46eb-b585-aa975d80a88c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Exploratory Data Analysis",
      "metadata": {
        "id": "sv6v51PFwt2j"
      }
    },
    {
      "cell_type": "code",
      "source": "# Gender Distribution Analysis\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# Gender distribution pie chart\ngender_counts = df['sex'].value_counts()\naxes[0].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', \n           startangle=140, colors=sns.color_palette('viridis', len(gender_counts)))\naxes[0].set_title('Gender Distribution')\n\n# Employment type distribution\nemployment_counts = df['full_or_part_time'].value_counts()\naxes[1].pie(employment_counts.values, labels=['Full-time', 'Part-time'], autopct='%1.1f%%',\n           startangle=140, colors=sns.color_palette('pastel', len(employment_counts)))\naxes[1].set_title('Employment Type Distribution')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"=== Gender Distribution ===\")\nprint(df['sex'].value_counts())\nprint(\"\\n=== Employment Type Distribution ===\")\nprint(df['full_or_part_time'].value_counts())",
      "metadata": {
        "id": "M4GKdlftbR8j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Salary Analysis\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Salary distribution histogram\naxes[0,0].hist(df['annual_salary'].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\naxes[0,0].set_title('Annual Salary Distribution')\naxes[0,0].set_xlabel('Annual Salary ($)')\naxes[0,0].set_ylabel('Frequency')\n\n# Salary by employment type\nsns.boxplot(data=df, x='full_or_part_time', y='annual_salary', ax=axes[0,1])\naxes[0,1].set_title('Salary by Employment Type')\naxes[0,1].set_ylabel('Annual Salary ($)')\n\n# Top 10 departments by employee count\ntop_depts = df['department'].value_counts().head(10)\nsns.barplot(y=top_depts.index, x=top_depts.values, ax=axes[1,0])\naxes[1,0].set_title('Top 10 Departments by Employee Count')\naxes[1,0].set_xlabel('Number of Employees')\n\n# Salary by top 5 departments\ntop_5_depts = df['department'].value_counts().head(5).index\ndf_top5 = df[df['department'].isin(top_5_depts)]\nsns.boxplot(data=df_top5, x='department', y='annual_salary', ax=axes[1,1])\naxes[1,1].set_title('Salary Distribution - Top 5 Departments')\naxes[1,1].set_xticklabels(axes[1,1].get_xticklabels(), rotation=45, ha='right')\naxes[1,1].set_ylabel('Annual Salary ($)')\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"=== Salary Statistics ===\")\nprint(df['annual_salary'].describe())",
      "metadata": {
        "id": "N559syNpw3E7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ced92d-5a0d-448c-ecc9-89dbe56818b6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 4. Feature Engineering and Clustering Analysis",
      "metadata": {
        "id": "YczAXdHdOXhH"
      }
    },
    {
      "cell_type": "code",
      "source": "# Feature Engineering for Clustering\n# Encode gender for numerical analysis\nsex_mapping = {'M': 0, 'F': 1, 'N': 2, 'U': 3}\ndf['sex_encoded'] = df['sex'].map(sex_mapping)\n\n# Prepare clustering features\nfeatures_for_clustering = ['annual_salary', 'sex_encoded']\nX_cluster = df[features_for_clustering].copy()\n\n# Handle missing values and scale features\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nX_cluster_imputed = imputer.fit_transform(X_cluster)\n\nscaler = StandardScaler()\nX_cluster_scaled = scaler.fit_transform(X_cluster_imputed)\n\nprint(\"=== Clustering Features Prepared ===\")\nprint(f\"Features: {features_for_clustering}\")\nprint(f\"Data shape after preprocessing: {X_cluster_scaled.shape}\")\nprint(\"\\n=== Gender Encoding ===\")\nprint(df['sex_encoded'].value_counts().sort_index())",
      "metadata": {
        "id": "H0VsnZxbw-Os"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# K-Means Clustering Analysis\ndef perform_kmeans_analysis(X_scaled, k_range=range(2, 8)):\n    \"\"\"Perform K-means clustering with optimal K selection.\"\"\"\n    inertias = []\n    silhouette_scores = []\n    \n    # Calculate inertia and silhouette scores for different K values\n    for k in k_range:\n        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n        cluster_labels = kmeans.fit_predict(X_scaled)\n        inertias.append(kmeans.inertia_)\n        sil_score = silhouette_score(X_scaled, cluster_labels)\n        silhouette_scores.append(sil_score)\n    \n    # Plot results\n    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Elbow method\n    axes[0].plot(k_range, inertias, marker='o', linewidth=2, markersize=8)\n    axes[0].set_title('Elbow Method for Optimal K')\n    axes[0].set_xlabel('Number of Clusters (K)')\n    axes[0].set_ylabel('Inertia')\n    axes[0].grid(True)\n    \n    # Silhouette scores\n    axes[1].plot(k_range, silhouette_scores, marker='s', color='orange', linewidth=2, markersize=8)\n    axes[1].set_title('Silhouette Score for Optimal K')\n    axes[1].set_xlabel('Number of Clusters (K)')\n    axes[1].set_ylabel('Silhouette Score')\n    axes[1].grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Find optimal K (highest silhouette score)\n    optimal_k = k_range[np.argmax(silhouette_scores)]\n    print(f\"\\\\n=== Optimal K Selection ===\")\n    print(f\"Recommended K based on highest silhouette score: {optimal_k}\")\n    print(f\"Silhouette score for K={optimal_k}: {max(silhouette_scores):.4f}\")\n    \n    return optimal_k\n\n# Perform clustering analysis\noptimal_k = perform_kmeans_analysis(X_cluster_scaled)",
      "metadata": {
        "id": "1VoR6Yh4x6cF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Apply K-Means with optimal K and visualize results\nkmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init='auto')\ndf['cluster'] = kmeans_final.fit_predict(X_cluster_scaled)\n\n# Analyze cluster characteristics\nprint(\"=== Cluster Analysis ===\")\ncluster_summary = df.groupby('cluster')[features_for_clustering].mean()\nprint(\"Mean values by cluster:\")\nprint(cluster_summary)\n\nprint(\"\\\\nCluster sizes:\")\nprint(df['cluster'].value_counts().sort_index())\n\n# Visualize clusters\nplt.figure(figsize=(12, 8))\nscatter = plt.scatter(df['annual_salary'], df['sex_encoded'], \n                     c=df['cluster'], cmap='viridis', alpha=0.6, s=50)\nplt.colorbar(scatter, label='Cluster')\nplt.xlabel('Annual Salary ($)')\nplt.ylabel('Gender (Encoded)')\nplt.title(f'Employee Clusters (K={optimal_k})')\nplt.grid(True, alpha=0.3)\n\n# Add gender labels\ny_labels = ['Male', 'Female', 'Neutral', 'Unknown']\nplt.yticks(range(4), y_labels)\n\nplt.tight_layout()\nplt.show()\n\n# Save processed dataset\ndf.to_csv(OUTPUT_FILE, index=False)\nprint(f\"\\\\nProcessed dataset saved to: {OUTPUT_FILE}\")",
      "metadata": {
        "id": "PTqitBsoyq9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "4fc30782-ea0c-43d8-add9-cd854ddfa024"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 5. Machine Learning Models",
      "metadata": {
        "id": "DyFunjNYyzoz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "be99aeae-6d26-471e-aeb2-80902daaf363"
      }
    },
    {
      "cell_type": "code",
      "source": "def create_ml_pipeline(numerical_features, categorical_features):\n    \"\"\"Create a preprocessing pipeline for machine learning models.\"\"\"\n    numerical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='median')),\n        ('scaler', StandardScaler())\n    ])\n    \n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False))\n    ])\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_features),\n            ('cat', categorical_transformer, categorical_features)\n        ],\n        remainder='passthrough'\n    )\n    \n    return preprocessor\n\ndef evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n    \"\"\"Evaluate a trained model and print results.\"\"\"\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n    \n    print(f\"\\\\n=== {model_name} Results ===\")\n    print(f\"Training Accuracy: {accuracy_score(y_train, y_pred_train):.4f}\")\n    print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n    \n    print(\"\\\\nTest Set Classification Report:\")\n    if len(np.unique(y_test)) == 2:\n        target_names = ['Class 0', 'Class 1']\n    else:\n        target_names = [f'Class {i}' for i in sorted(np.unique(y_test))]\n    \n    print(classification_report(y_test, y_pred_test, target_names=target_names, zero_division=0))\n    \n    return y_pred_test",
      "metadata": {
        "id": "fQarTYSKQH-u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "ca270383-0a6f-4e09-b965-0f4dd7b4def6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 5.1 Gender Prediction Model",
      "metadata": {
        "id": "rMo2bpGhRqTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "a7e71094-b58a-4d26-ac38-44779777046f"
      }
    },
    {
      "cell_type": "code",
      "source": "# Gender Prediction Model\n# Prepare features (excluding name-related and target columns)\ngender_exclude_cols = ['name', 'surname', 'first_name', 'sex', 'sex_encoded', \n                      'typical_hours', 'hourly_rate', 'cluster']\nX_gender = df.drop(columns=gender_exclude_cols, errors='ignore')\ny_gender = df['sex_encoded'].dropna()\n\n# Align X and y after removing NaN values from target\nX_gender = X_gender.loc[y_gender.index]\n\n# Identify feature types\nnumerical_features = X_gender.select_dtypes(include=np.number).columns.tolist()\ncategorical_features = X_gender.select_dtypes(include='object').columns.tolist()\n\nprint(\"=== Gender Prediction Setup ===\")\nprint(f\"Features: {X_gender.columns.tolist()}\")\nprint(f\"Numerical features: {numerical_features}\")\nprint(f\"Categorical features: {categorical_features}\")\nprint(f\"Target distribution:\\\\n{y_gender.value_counts().sort_index()}\")\n\n# Split data\nX_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n    X_gender, y_gender, test_size=0.25, random_state=42, stratify=y_gender\n)\n\n# Create and train model\npreprocessor_gender = create_ml_pipeline(numerical_features, categorical_features)\ngender_model = Pipeline([\n    ('preprocessor', preprocessor_gender),\n    ('classifier', LogisticRegression(solver='lbfgs', multi_class='auto', \n                                    class_weight='balanced', random_state=42, max_iter=1000))\n])\n\nprint(\"\\\\nTraining gender prediction model...\")\ngender_model.fit(X_train_g, y_train_g)\n\n# Evaluate model\nevaluate_model(gender_model, X_train_g, X_test_g, y_train_g, y_test_g, \"Gender Prediction\")",
      "metadata": {
        "id": "Vs62OQidblCr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### 5.2 High Earner Prediction Model",
      "metadata": {
        "id": "a4kA_LXJd8Hb"
      }
    },
    {
      "cell_type": "code",
      "source": "# High Earner Prediction Model\n# Create target variable: top 25% earners\nsalary_threshold = df['annual_salary'].quantile(0.75)\ndf['is_top_earner'] = (df['annual_salary'] >= salary_threshold).astype(int)\n\nprint(f\"=== High Earner Analysis ===\")\nprint(f\"Salary threshold (75th percentile): ${salary_threshold:,.2f}\")\nprint(f\"Top earner distribution:\\\\n{df['is_top_earner'].value_counts(normalize=True)}\")\n\n# Prepare features (exclude salary-related columns to avoid data leakage)\nearner_exclude_cols = ['name', 'surname', 'first_name', 'sex', \n                      'annual_salary', 'hourly_rate', 'typical_hours', \n                      'is_top_earner', 'cluster']\nX_earner = df.drop(columns=earner_exclude_cols, errors='ignore')\ny_earner = df['is_top_earner']\n\n# Identify feature types  \nnumerical_features_earner = X_earner.select_dtypes(include=np.number).columns.tolist()\ncategorical_features_earner = X_earner.select_dtypes(include='object').columns.tolist()\n\nprint(f\"\\\\nFeatures for earning prediction: {X_earner.columns.tolist()}\")\n\n# Split data\nX_train_e, X_test_e, y_train_e, y_test_e = train_test_split(\n    X_earner, y_earner, test_size=0.25, random_state=42, stratify=y_earner\n)\n\n# Create and train model\npreprocessor_earner = create_ml_pipeline(numerical_features_earner, categorical_features_earner)\nearner_model = Pipeline([\n    ('preprocessor', preprocessor_earner),\n    ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced', \n                                    random_state=42, max_iter=1000))\n])\n\nprint(\"\\\\nTraining high earner prediction model...\")\nearner_model.fit(X_train_e, y_train_e)\n\n# Evaluate model\ny_pred_earner = evaluate_model(earner_model, X_train_e, X_test_e, y_train_e, y_test_e, \"High Earner Prediction\")",
      "metadata": {
        "id": "ZFnhQcC0fykk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6728a5-932c-4d92-f375-6bd59445c540"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# ROC Curve Analysis for High Earner Model\ny_pred_proba = earner_model.predict_proba(X_test_e)[:, 1]\n\n# Calculate ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_e, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\n# Plot ROC curve\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random classifier')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve - High Earner Prediction')\nplt.legend(loc=\"lower right\")\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_test_e, y_pred_earner)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Not Top Earner', 'Top Earner'],\n            yticklabels=['Not Top Earner', 'Top Earner'])\nplt.title('Confusion Matrix - High Earner Prediction')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()",
      "metadata": {
        "id": "AYXdPukTf680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "a2873d1c-e6f8-4c4a-baf5-e10d4ffe39e4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 6. Summary and Conclusions\n\nThis analysis of the Chicago Active Employee dataset revealed several key insights:\n\n### Key Findings:\n1. **Gender Distribution**: The workforce shows a clear gender imbalance with males significantly outnumbering females\n2. **Salary Patterns**: Strong correlation between job titles, departments, and compensation levels\n3. **Employee Clustering**: K-means clustering successfully identified distinct employee groups based on salary and gender\n4. **Predictive Models**: \n   - Gender prediction achieved moderate accuracy using job characteristics\n   - High earner prediction showed strong performance (>90% accuracy) using department and job title features\n\n### Technical Achievements:\n- Enhanced gender detection using comprehensive name lists\n- Successful data preprocessing with missing value handling\n- Effective feature engineering for machine learning models\n- Robust model evaluation with multiple metrics\n\n### Dataset Information:\n- **Original Shape**: ~31,000 employees with 8 core attributes\n- **Processed Shape**: ~30,857 employees with enhanced features\n- **Output**: Cleaned dataset saved as `chicago_dataset_cleaned.csv`\n\nThis analysis provides a comprehensive view of Chicago's municipal workforce and demonstrates effective data science techniques for employee analytics.",
      "metadata": {}
    }
  ]
}